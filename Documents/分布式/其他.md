# 分布式Session解决方案
* 使用cookie来完成（很明显这种不安全的操作并不可靠）
* 使用Nginx中的ip绑定策略，同一个ip只能在指定的同一个机器访问（不支持负载均衡）
* 利用数据库同步session（效率不高）
* 使用tomcat内置的session同步（同步可能会产生延迟）
* 使用token代替session
* 我们使用spring-session以及集成好的解决方案，存放在redis中

就是当Web服务器接收到http请求后，当请求进入对应的Filter进行过滤，将原本需要由web服务器创建会话的过程转交给Spring-Session进行创建，
本来创建的会话保存在Web服务器内存中，通过Spring-Session创建的会话信息可以保存第三方的服务中，如：redis,mysql等。
Web服务器之间通过连接第三方服务来共享数据，实现Session共享！

# 思路
1. webserver 集群
2. 分库，分表（水平拆分）,分布式数据库
3. 分布式数据缓存
4. 消息系统：典型的异步处理，应用解耦，流量削锋和消息通讯四个场景。

# 订单状态流转的幂等性
1. 全局唯一ID
如果使用全局唯一ID，就是根据业务的操作和内容生成一个全局ID，在执行操作前先根据这个全局唯一ID是否存在，来判断这个操作是否已经执行。如果不存在则把全局ID，存储到存储系统中，比如数据库、Redis等。如果存在则表示该方法已经执行。

2. 去重表
把创建支付单据和写入去去重表，放在一个事务中，如果重复创建，数据库会抛出唯一约束异常，操作就会回滚。

3. 插入或更新
其中商品的ID和品类的ID可以构成唯一索引，并且在数据表中也增加了唯一索引。这时就可以使用InsertOrUpdate操作

4. 多版本控制 
这时我们就可以在更新的接口中增加一个版本号，来做幂等

5. 更新业务
更新业务接口幂等性解决方案一般是通过各种层面的锁和CAS机制；

# 接口超时
核心逻辑的调用会有重试机制+重试次数达到设置的次数，进入消息队列+扫描任务定时处理

# 接口限流
1. guava提供工具库里的RateLimiter类(内部采用令牌捅算法实现)进行限流
接口限流可以在nginx层面做限流，也可以在网关层面做限流，这里在网关层面做限流，基于guava框架来做网关限流。
它的大致意思就是每一个请求进来先到桶里去拿令牌，拿到令牌的请求放行，假设你设置了1000个令牌，如果拿完了，那么后面来调接口的请求就需要排队等有新的令牌才能调用该接口。
2. 使用Redis实现，存储两个key，一个用于计时，一个用于计数。请求每调用一次，计数器增加1，若在计时器时间内计数器未超过阈值，则可以处理任务
3. 使用Java自带delayqueue的延迟队列实现
4. Zuul
限流配置
limit 单位时间内允许访问的个数
quota 单位时间内允许访问的总时间（统计每次请求的时间综合）
refresh-interval 单位时间设置

# RPC
RPC是只远程过程调用，也就是说两台服务器A,B, 一个应用部署在A服务器上，另一个应用部署在B服务器上，A服务器上的应用想要调用B服务器上的应用提供的方法/函数，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语意和传递调用的参数。
整个调用过程，主要经历如下几个步骤：
1. 建立通讯
2. 服务寻址（zookeeper）
3. 网络传输（序列化，反序列化，调用）
# webservice
SOAP可以简单理解为http + xml。
WSDL(Web Services Description Language)，即网络服务描述语言，可描述WebService服务。
WebService是一种跨语言和跨操作系统的远程调用技术。

# cdn
CDN的基本原理是广泛采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区或网络中，在用户访问网站时，利用全局负载技术将用户的访问指向距离最近的工作正常的缓存服务器上，由缓存服务器直接响应用户请求。

# 流量削峰总结(双11秒杀)
## 前端设计方案
1. 对于秒杀这样的高并发场景业务，最基本的原则就是将请求拦截在系统上游，降低下游压力。如果不在前端拦截很可能造成数据库(mysql、oracle等)读写锁冲突，甚至导致死锁，最终还有可能出现雪崩等场景。
- 前端设计方案
 页面静态化：将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。
 禁止重复提交：用户提交之后按钮置灰，禁止重复提交
 用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取IP限流
## 后端设计方案
1. 服务端控制器层(网关层)
2. 限制uid（UserID）访问频率：我们上面拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问uid，限制访问频率。
3. 充分利用缓存(redis等)：增加QPS，从而加大整个集群的吞吐量。
 利用缓存应对读请求：比如双11秒杀抢购，是典型的读多写少业务，大部分请求是查询请求，所以可以利用缓存分担数据库压力。
 利用缓存应对写请求：缓存也是可以应对写请求的，比如我们就可以把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。
4. 高峰值流量是压垮系统很重要的原因，所以需要Kafka等消息队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。
 采用消息队列缓存请求：既然服务层知道库存只有100台手机，那完全没有必要把100W个请求都传递到数据库啊，那么可以先把这些请求都写到消息队列缓存一下，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。
## 数据库层
数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。所以，上面通过在服务层引入队列和缓存，让最底层的数据库高枕无忧。
## 秒杀架构设计总结：
1. 限流： 鉴于只有少部分用户能够秒杀成功，所以要限制大部分流量，只允许少部分流量进入服务后端。
2. 削峰：对于秒杀系统瞬时会有大量用户涌入，所以在抢购一开始会有很高的瞬间峰值。高峰值流量是压垮系统很重要的原因，所以如何把瞬间的高流量变成一段时间平稳的流量也是设计秒杀系统很重要的思路。实现削峰的常用的方法有利用缓存和消息中间件等技术。
3. 异步处理：秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，其实异步处理就是削峰的一种实现方式。
4. 内存缓存：秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。
5. 可拓展：当然如果我们想支持更多用户，更大的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓展机器就好了。像淘宝、京东等双十一活动时会增加大量机器应对交易高峰。




