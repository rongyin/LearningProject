# 分表分库
1. 单表数据量太大，会极大影响你的 sql 执行的性能,单表到几百万的时候，性能就会相对差一些了
2. 一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右
3. 分库分表中间件
- Sharding-jdbc
- Mycat
4. 分库分表的方式
- 一种是按照 range 来分
range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。

- 或者是按照某个字段 hash 一下均匀分散
hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。


# 分库分表之后，id 主键如何处理？
1. 专门开一个服务出来，这个服务每次就拿到当前 id 最大值，
然后自己递增几个 id，一次性返回一批 id，然后再把当前最大 id 值修改成递增几个 id 之后的一个值

2. 设置数据库 sequence 或者表自增字段步长

3. UUID

4. snowflake 算法  64 位的 long 型的 id
1 bit符号位置+41bit时间戳+10bit工作机房机器id+12 bit这个是用来记录同一个毫秒内产生的不同 id

# 分表分库方案
1. 停机迁移方案
数据量小写个工具，多弄几台机器并行跑，1小时数据就导完了。这没有问题。
2. 双写迁移方案
简单来说，就是在线上系统里面，之前所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改，这就是所谓的双写，同时写俩库，老库和新库。

3. 扩容
- 设定好几台数据库服务器，每台服务器上几个库，每个库多少个表，推荐是 32 库 * 32 表，对于大部分公司来说，可能几年都够了。
- 路由的规则，orderId 模 32 = 库，orderId / 32 模 32 = 表
- 扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
- 由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
- 我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
- 重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

# 如何保证缓存与数据库的双写一致性？
1. Cache Aside Pattern
* 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
* 更新的时候，先更新数据库，然后再删除缓存。原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。
2. 问题
数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改
2. 解决方案如下：
更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个 jvm 内部队列中。
一定要注意读超时的问题

# 缓存雪崩
- 对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。
- 缓存雪崩的事前事中事后的解决方案如下。
* 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。
* 事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
* 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

# 缓存穿透
- 黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。
- 解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。

# 缓存击穿
- 缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。

- 解决方式也很简单，可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。

# 并发竞争
- 这个也是线上非常常见的一个问题，就是多客户端同时并发写一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。
- 而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。
- 某个时刻，多个系统实例都去更新某个 key。可以基于 zookeeper 实现分布式锁。每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。











